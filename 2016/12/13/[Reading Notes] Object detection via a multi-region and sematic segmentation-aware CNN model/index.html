<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
<script data-ad-client="ca-pub-1831623022964098" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/C_Meng.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/C_Meng.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/C_Meng.png">
  <link rel="mask-icon" href="/images/C_Meng.png" color="#222">
  <meta name="google-site-verification" content="-WnFIB8dOJwdL5b4iIfg6bNp1o-p5XnbyMIPVWXr6N0">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"imonce.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="AbstractThis article propose an object detection system that relies on a multi-region deep convolutional neural network that also encodes sematic segmentation-aware features. The module aims at captur">
<meta name="keywords" content="Reading Notes,Object Detection,CNN,multi-region,Sematic segmentation-aware">
<meta property="og:type" content="article">
<meta property="og:title" content="[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model">
<meta property="og:url" content="https://imonce.github.io/2016/12/13/[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model/index.html">
<meta property="og:site_name" content="C_Meng PSNA">
<meta property="og:description" content="AbstractThis article propose an object detection system that relies on a multi-region deep convolutional neural network that also encodes sematic segmentation-aware features. The module aims at captur">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ohykn376o.bkt.clouddn.com/OBDE2.png">
<meta property="og:image" content="http://ohykn376o.bkt.clouddn.com/OBDE1.png">
<meta property="og:updated_time" content="2020-01-04T07:58:24.550Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model">
<meta name="twitter:description" content="AbstractThis article propose an object detection system that relies on a multi-region deep convolutional neural network that also encodes sematic segmentation-aware features. The module aims at captur">
<meta name="twitter:image" content="http://ohykn376o.bkt.clouddn.com/OBDE2.png">

<link rel="canonical" href="https://imonce.github.io/2016/12/13/[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'default'
  };
</script>

  <title>[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model | C_Meng PSNA</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">C_Meng PSNA</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Never wait for the storm to pass, just dance in the rain.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">207</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">32</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">133</span></a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/imonce" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="default">
    <link itemprop="mainEntityOfPage" href="https://imonce.github.io/2016/12/13/[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/C_Meng.png">
      <meta itemprop="name" content="C_Meng">
      <meta itemprop="description" content="A stupid old man with a humble learning heart. And his dog.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="C_Meng PSNA">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2016-12-13 22:58:00" itemprop="dateCreated datePublished" datetime="2016-12-13T22:58:00+08:00">2016-12-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-01-04 15:58:24" itemprop="dateModified" datetime="2020-01-04T15:58:24+08:00">2020-01-04</time>
              </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2016/12/13/[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2016/12/13/[Reading Notes] Object detection via a multi-region and sematic segmentation-aware CNN model/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>This article propose an object detection system that relies on a multi-region deep convolutional neural network that also encodes sematic segmentation-aware features. The module aims at capturing a diverse set of discriminative appearance factors and exhibits localization sensitivity that is essential for accurate object localization. They exploit the above properties of their recognition module by intergrating it on an iterative localization mechanism that alternates between socring a box proposal and refgining its location with a deep CNN regression model. And consiquently, they detect objects with very high localization accuracy.</p>
<h2 id="I-Introduction"><a href="#I-Introduction" class="headerlink" title="I. Introduction"></a>I. Introduction</h2><p>The definition of object detection:</p>
<blockquote>
<p>Given an image return all the instances of one or more type of objects in form of bounding boxes that tightly enclose them.</p>
</blockquote>
<a id="more"></a>

<p>Overfeat:</p>
<blockquote>
<p>Using two CNN models that apply in a sliding window fashion on multiple scales of an image. The first is used to classify if a window contains an object. The second is to predict the true bounding box location of the object. And use <strong>greedy algorithm</strong> in the end to merge them.</p>
</blockquote>
<p>R-CNN:</p>
<blockquote>
<p>Using <strong>Alex Krizhevsky’s Net</strong>  to extract features from box proposals provided by selective search and then it classifies them with class specific linear SVMs.</p>
</blockquote>
<p>How to further advance the state-of-the-art on object detection?</p>
<blockquote>
<p>Focusing on object representation and object localization. </p>
</blockquote>
<p>Object representation:</p>
<blockquote>
<p>Indeed features matter a lot on object detection. Instead of proposing only a network architecture that is deeper, here they also opt for an architecture of greater width. And that was accomplished at two levels:</p>
</blockquote>
<blockquote>
<ol>
<li>They want their object representation to capture several different aspects of an object. To achieve this, they propose a multi-component CNN model (multi-region CNN). Each component of it is steered to focus on a different region.</li>
<li>They wish to enrich the above representation so that it also captures semantic segmentation information</li>
</ol>
</blockquote>
<p>Object localization:</p>
<blockquote>
<p>They attempt to built a more powerful localization system that combines their multi-region CNN model with a CNN-model for bounding box regression, which are used within an iterative scheme that alternates between scoring candidate boxes and reﬁning their coordinates.</p>
</blockquote>
<p>Their Contributions:</p>
<blockquote>
<ol>
<li>They develop a multi-region CNN recognition model that yields an enriched object representation capable of capturing a diversity of discriminative appearance factors and of exhibiting localization sensitivity that is desired for the task of accurate object localization.</li>
<li>They furthermore extend the above model by proposing a uniﬁed neural network architecture that also learns semantic segmentation-aware CNN features for the task of object detection.</li>
<li>They show how to significantly improve the localization capability by coupling the aforementioned CNN recognition model with a CNN model for bounding box regression.</li>
<li>Their detection system achieves <strong>mAP</strong> of 78.2% and 73.9% on <strong>VOC2007 and VOC2012</strong> detection challenges respectively.</li>
</ol>
</blockquote>
<h2 id="II-Multi-Region-CNN-Model"><a href="#II-Multi-Region-CNN-Model" class="headerlink" title="II. Multi-Region CNN Model"></a>II. Multi-Region CNN Model</h2><ol>
<li>Activation maps module<ul>
<li>This part of the network gets as input the entire image and outputs activation maps (feature maps) by forwarding it through a sequence of convolutional layers.</li>
</ul>
</li>
<li>Region adaptation module<ul>
<li>Given a region R on the image and the activation maps of the image, this module projects R on the activation maps, crops the activations that lay inside it, pools them with a spatially adaptive (max-)pooling layer, and then forwards them through a multi-layer network.</li>
</ul>
</li>
</ol>
<p>This is the architecture of the Multi-Region CNN model:</p>
<p><img src="http://ohykn376o.bkt.clouddn.com/OBDE2.png" alt="Figure2"></p>
<p>There are two aims of that:</p>
<blockquote>
<ol>
<li>to force the network to capture various complementary aspects of the objects appearance, thus leading to a much richer and more robust object representation</li>
<li>to also make the resulting representation more sensitive to inaccurate localization, which is also crucial for object detection</li>
</ol>
</blockquote>
<p><strong><em>The regions they deploy:</em></strong></p>
<blockquote>
<ol>
<li>Original candidate box</li>
<li>Half boxes</li>
<li>Central Regions</li>
<li>Border Regions</li>
<li>Contextual Region</li>
</ol>
</blockquote>
<p><strong><em>Why these regions helps?</em></strong></p>
<blockquote>
<ol>
<li>Discriminative feature diversification</li>
<li>Localization-aware representation</li>
</ol>
</blockquote>
<h2 id="III-Semantic-Segmentation-Aware-CNN-Model"><a href="#III-Semantic-Segmentation-Aware-CNN-Model" class="headerlink" title="III. Semantic Segmentation-Aware CNN Model"></a>III. Semantic Segmentation-Aware CNN Model</h2><p><img src="http://ohykn376o.bkt.clouddn.com/OBDE1.png" alt="figure4"></p>
<ul>
<li>Activation maps module for semantic segmentation aware features<ul>
<li><strong><em>Weakly supervised training</em></strong>(see Figure 4)</li>
<li>Activation maps</li>
</ul>
</li>
<li>Region adaptation module for semantic segmentation aware features</li>
</ul>
<p>They combine the Multi-Region CNN features and the semantic segmentation aware CNN features by concatenating them. The resulting network thus jointly learns deep features of both types during training.</p>
<h2 id="IV-Object-Localization"><a href="#IV-Object-Localization" class="headerlink" title="IV. Object Localization"></a>IV. Object Localization</h2><p>There are three main components in this section:</p>
<ol>
<li><p>CNN region adaptation module for bounding box regression</p>
<ul>
<li>It is applied on top of the activation maps produced from the Multi-Region CNN model and, instead of a typical one-layer ridge regression model, consists of two hidden fully connected layers and one prediction layer that outputs 4 values per category. In order to allow it to predict the location of object instances that are not in the close proximity of any of the initial candidate boxes, we Use as region a box obtained by enlarging the candidate box by a factor of 1.3. This combination offers a significant boost on the detection performance of out system by allowing it to make more accurate predictions and for more distant objects.</li>
</ul>
</li>
<li><p>Iterative Localization</p>
<ul>
<li>Their localization scheme starts from the selective search proposals and works by iteratively scoring them and refining their coordinates.</li>
</ul>
</li>
<li><p>Bounding box voting</p>
<ul>
<li>Because of the multiple regression steps, the generated boxes will be highly concentrated around the actual objects of interest. They exploit this “by-product” of the iterative localization scheme by adding a step of bounding box voting.</li>
</ul>
</li>
</ol>
<h2 id="V-Implementation-Details"><a href="#V-Implementation-Details" class="headerlink" title="V. Implementation Details"></a>V. Implementation Details</h2><blockquote>
<p>For all the CNN models involved in their proposed system, we used the publicly available <strong>16-layers VGG model</strong> pre-trained on ImageNet for the task of image classification.</p>
</blockquote>
<p>Multi-Region CNN model</p>
<blockquote>
<p>Its activation maps module consistes of the convolustional part of the 16-layers VGG-Net that outputs 512 feature channels. The max-pooling layer right after the last convolutional layer is omitted on this module. Each region adaptation module inherits the fully connected layers of the 16-layers VGG-Net and is fine-tuned separately from the others.</p>
</blockquote>
<p>Semantic segmentation-aware CNN model</p>
<blockquote>
<p>The activation maps module architecture consists of the 16-layers VGG-Net without the last classification layer and transformed to a Fully Convolutional Network.</p>
</blockquote>
<p>Classification SVMs</p>
<blockquote>
<p>The ground truth bounding boxes are used as positive samples and the selective search proposals that overlap with the ground truth boxes by less than 0.3, are used as negative samples.</p>
</blockquote>
<p>CNN region adaptation module for bounding box regression</p>
<blockquote>
<p>The region adaptation module for bounding box regression inherits the fully connected hidden layers of the 16-layers VGG-Net. As a loss function they use the euclidean distance between the target values and the network predictions.</p>
</blockquote>
<h2 id="VI-Experimental-Evaluation"><a href="#VI-Experimental-Evaluation" class="headerlink" title="VI. Experimental Evaluation"></a>VI. Experimental Evaluation</h2><ol>
<li>Results on PASCAL VOC2007</li>
<li>Detection error analysis</li>
<li>Results on PASCAL VOC2012</li>
</ol>
<h2 id="VII-Conclusion"><a href="#VII-Conclusion" class="headerlink" title="VII. Conclusion"></a>VII. Conclusion</h2><p>Two key factors:</p>
<ol>
<li>the diversification of the discriminative appearance factors that it captures by steering its focus on different regions of the object</li>
<li>the encoding of semantic segmentation-aware features. By using it in the context of a CNN-based localization refinement scheme, they showed that it achieves excellent results that surpass the state-of-the-are by a significant margin</li>
</ol>

    </div>

    
    
    
        <div class="reward-container">
  <div>点击这个按钮，会有好事发生哦~(>w<)~</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="C_Meng WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="C_Meng Alipay">
        <p>Alipay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/paypal.png" alt="C_Meng PayPal">
        <p>PayPal</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Reading-Notes/" rel="tag"># Reading Notes</a>
              <a href="/tags/Object-Detection/" rel="tag"># Object Detection</a>
              <a href="/tags/CNN/" rel="tag"># CNN</a>
              <a href="/tags/multi-region/" rel="tag"># multi-region</a>
              <a href="/tags/Sematic-segmentation-aware/" rel="tag"># Sematic segmentation-aware</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2016/12/11/[Reading Notes] UniCrawl- A Practical Geographically Distributed Web Crawler/" rel="prev" title="[Reading Notes] UniCrawl: A Practical Geographically Distributed Web Crawler">
      <i class="fa fa-chevron-left"></i> [Reading Notes] UniCrawl: A Practical Geographically Distributed Web Crawler
    </a></div>
      <div class="post-nav-item">
    <a href="/2016/12/14/Chainer入门教程(上)：在Chainer中做线性回归/" rel="next" title="Chainer入门教程(上)：在Chainer中做线性回归">
      Chainer入门教程(上)：在Chainer中做线性回归 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1831623022964098"
     data-ad-slot="5648729926"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#I-Introduction"><span class="nav-number">2.</span> <span class="nav-text">I. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#II-Multi-Region-CNN-Model"><span class="nav-number">3.</span> <span class="nav-text">II. Multi-Region CNN Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#III-Semantic-Segmentation-Aware-CNN-Model"><span class="nav-number">4.</span> <span class="nav-text">III. Semantic Segmentation-Aware CNN Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IV-Object-Localization"><span class="nav-number">5.</span> <span class="nav-text">IV. Object Localization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#V-Implementation-Details"><span class="nav-number">6.</span> <span class="nav-text">V. Implementation Details</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VI-Experimental-Evaluation"><span class="nav-number">7.</span> <span class="nav-text">VI. Experimental Evaluation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VII-Conclusion"><span class="nav-number">8.</span> <span class="nav-text">VII. Conclusion</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="C_Meng"
      src="/images/C_Meng.png">
  <p class="site-author-name" itemprop="name">C_Meng</p>
  <div class="site-description" itemprop="description">A stupid old man with a humble learning heart. And his dog.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">133</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">207</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/imonce" title="GitHub → https://github.com/imonce" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:imonce@outlook.com" title="E-Mail → mailto:imonce@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/3912390829/profile?topnav=1&wvr=6&is_all=1" title="Weibo → https://weibo.com/3912390829/profile?topnav=1&wvr=6&is_all=1" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/moescee" title="Twitter → https://twitter.com/moescee" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1831623022964098"
     data-ad-slot="5648729926"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">C_Meng</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>


  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1279293837&web_id=1279293837"></script>
  </div>






      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  <script src="/js/local-search.js"></script>








<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'hBUFmUyAMBRRHULc0Y4SPPzw-gzGzoHsz',
      appKey     : 'WBQPPWjmwGWqvQcLqprPq0xs',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
